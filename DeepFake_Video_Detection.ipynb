{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRDOguH6_cLn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score,confusion_matrix\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, TimeDistributed, Dropout\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_frame(frame):\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame = cv2.resize(frame, (112, 112))\n",
        "    return frame / 255.0"
      ],
      "metadata": {
        "id": "807MF0tF_qC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for face detection\n",
        "def detect_face(frame):\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "    if len(faces) > 0:\n",
        "        (x, y, w, h) = faces[0]\n",
        "        return frame[y:y+h, x:x+w]\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "7dDRB5ch_sf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load video and extract frames\n",
        "def extract_frames(video_path, num_frames=10):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "    while len(frames) < num_frames and cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_count % 3 == 0:  # Sample every 3rd frame\n",
        "            face = detect_face(frame)\n",
        "            if face is not None:\n",
        "                face = preprocess_frame(face)\n",
        "                frames.append(face)\n",
        "        frame_count += 1\n",
        "    cap.release()\n",
        "\n",
        "    # If we couldn't extract enough frames, duplicate the last frame\n",
        "    while len(frames) < num_frames:\n",
        "        frames.append(frames[-1] if frames else np.zeros((112, 112, 3)))\n",
        "\n",
        "    return np.array(frames[:num_frames])\n"
      ],
      "metadata": {
        "id": "ENdedRlL_u1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "def load_dataset(real_dir, fake_dir,max_videos=100):\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    # Load real videos\n",
        "    for video_name in os.listdir(real_dir):\n",
        "        video_path = os.path.join(real_dir, video_name)\n",
        "        frames = extract_frames(video_path)\n",
        "        X.append(frames)\n",
        "        y.append(0)  # 0 for real\n",
        "\n",
        "    # Load fake videos\n",
        "    for video_name in os.listdir(fake_dir):\n",
        "        video_path = os.path.join(fake_dir, video_name)\n",
        "        frames = extract_frames(video_path)\n",
        "        X.append(frames)\n",
        "        y.append(1)  # 1 for fake\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "JS4634NF_yAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "def build_model(input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Feature extraction using ResNet50\n",
        "    resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(112, 112, 3))\n",
        "    model.add(TimeDistributed(resnet, input_shape=input_shape))\n",
        "    model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "    # LSTM for sequence analysis\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(LSTM(64, return_sequences=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LQrkx6yF_0YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot training history\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "UWLpB3AP_2us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, save_path):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "    print(f\"Confusion matrix saved to {save_path}\")"
      ],
      "metadata": {
        "id": "95QL_a4WMO2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import zipfile\n",
        "\n",
        "def load_and_preprocess_dataset(real_dir, fake_dir, preprocessed_data_path):\n",
        "    try:\n",
        "        if os.path.exists(preprocessed_data_path):\n",
        "            print(\"Loading preprocessed dataset...\")\n",
        "            with np.load(preprocessed_data_path) as data:\n",
        "                X = data['X']\n",
        "                y = data['y']\n",
        "        else:\n",
        "            raise FileNotFoundError(\"Preprocessed data file not found.\")\n",
        "    except (FileNotFoundError, zipfile.BadZipFile):\n",
        "        print(\"Preprocessed data not found or corrupted. Processing raw dataset...\")\n",
        "        X, y = load_dataset(real_dir, fake_dir)\n",
        "        np.savez_compressed(preprocessed_data_path, X=X, y=y)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "X0O7Vwwi_5Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X, y):\n",
        "    # Split the dataset\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build and train the model\n",
        "    input_shape = (10, 112, 112, 3)  # (num_frames, height, width, channels)\n",
        "    model = build_model(input_shape)\n",
        "\n",
        "    # Define callbacks\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_accuracy')\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=100,\n",
        "        batch_size=16,\n",
        "        callbacks=[early_stopping, model_checkpoint]\n",
        "    )\n",
        "\n",
        "    # Plot and save training history\n",
        "    plot_history(history)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = (y_pred > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "    precision = precision_score(y_test, y_pred_classes)\n",
        "    recall = recall_score(y_test, y_pred_classes)\n",
        "    f1 = f1_score(y_test, y_pred_classes)\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "     # Plot and save confusion matrix\n",
        "    plot_confusion_matrix(y_test, y_pred_classes, 'confusion_matrix.png')\n",
        "\n",
        "    return model, accuracy, precision, recall, f1\n"
      ],
      "metadata": {
        "id": "Dg-cJczJ_7ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_video(video_path, model):\n",
        "    frames = extract_frames(video_path)\n",
        "    frames = np.expand_dims(frames, axis=0)  # Add batch dimension\n",
        "    prediction = model.predict(frames)\n",
        "    return prediction[0][0]"
      ],
      "metadata": {
        "id": "LMltD-IH_-hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    real_dir = \"/content/drive/MyDrive/RFvideos/real\"\n",
        "    fake_dir = \"/content/drive/MyDrive/RFvideos/fake\"\n",
        "    preprocessed_data_path = \"/content/drive/MyDrive/RFvideos/preprocessed_data.npz\"\n",
        "    model_path = \"/content/drive/MyDrive/RFvideos/best_model.keras\"\n",
        "\n",
        "    X, y = load_and_preprocess_dataset(real_dir, fake_dir, preprocessed_data_path)\n",
        "\n",
        "    if os.path.exists(model_path):\n",
        "        print(\"Loading existing model...\")\n",
        "        model = load_model(model_path)\n",
        "\n",
        "        # Evaluate the model\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_classes = (y_pred > 0.5).astype(int).flatten()\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "        precision = precision_score(y_test, y_pred_classes)\n",
        "        recall = recall_score(y_test, y_pred_classes)\n",
        "        f1 = f1_score(y_test, y_pred_classes)\n",
        "\n",
        "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "        # Plot and save confusion matrix\n",
        "        plot_confusion_matrix(y_test, y_pred_classes, 'confusion_matrix.png')\n",
        "\n",
        "    else:\n",
        "        print(\"Training new model...\")\n",
        "        model, accuracy, precision, recall, f1 = train_model(X, y)\n",
        "\n",
        "   # Test the model on a new video\n",
        "    test_video_path = \"/content/drive/MyDrive/RFvideos/01__kitchen_pan.mp4\"\n",
        "    result = predict_video(test_video_path, model)\n",
        "    print(f\"Prediction: {result:.4f}\")\n",
        "    print(f\"The video is {'likely fake' if result > 0.5 else 'likely real'}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htxp4JTcAAmo",
        "outputId": "7574d63f-48d5-441f-b852-869293ae49e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading preprocessed dataset...\n",
            "Loading existing model...\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 25s/step\n",
            "Test Accuracy: 0.8750\n",
            "Precision: 0.8500\n",
            "Recall: 0.8947\n",
            "F1 Score: 0.8718\n",
            "Confusion matrix saved to confusion_matrix.png\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611ms/step\n",
            "Prediction: 0.3117\n",
            "The video is likely real\n"
          ]
        }
      ]
    }
  ]
}